---
layout: post
title: 核心指标与监控指标
date: 2021-01-02
tags: kubernetes
---
### 一、核心指标监控之metrics-server

> 在最初的系统资源监控，是通过`cAdvisor`去收集单个节点以及相关Pod资源的指标数据，但是这一功能仅能够满足单个节点，在集群日益庞大的过程中，该功能就显得low爆了。于是将各个节点的指标数据进行汇聚并通过一个借口进行向外暴露传送是必要的。
> 
> `Heapster`就是这样的一种方式，通过为集群提供指标API和实现并进行监控，它是集群级别的监控和事件数据的聚合工具，但是一个完备的Heapster监控体系是需要进行数据存储的，为此其解决方案就是引入了`Influxdb`作为后端数据的持久存储，`Grafana`作为可视化的接口。原理就是Heapster从各个节点上的cAdvisor采集数据并存储到Influxdb中，再由Grafana展示。原理图如下：

![](/images/posts/06_k8s/16/1.png)

> 时代在变迁，陈旧的东西将会被淘汰，由于功能和系统发展的需求，Heapster无法满足k8s系统监控的需求，为此在Kubernetes 1.7版本以后引入了自定义指标(custom metrics API)，在1.8版本引入了资源指标（resource metrics API）。逐渐地Heapster用于提供核心指标API的功能也被聚合方式的指标API服务器`metrics-server`所替代。

**在新一代的Kubernetes指标监控体系当中主要由核心指标流水线和监控指标流水线组成：**

- 核心指标流水线：

是指由kubelet、、metrics-server以及由API server提供的api组成，它们可以为K8S系统提供核心指标，从而了解并操作集群内部组件和程序。其中相关的指标包括CPU的累积使用率、内存实时使用率，Pod资源占用率以及容器磁盘占用率等等。其中核心指标的获取原先是由heapster进行收集，但是在1.11版本之后已经被废弃，从而由新一代的metrics-server所代替对核心指标的汇聚。核心指标的收集是必要的。如下图：

![](/images/posts/06_k8s/16/2.png)

- 监控指标流水线：

用于从系统收集各种指标数据并提供给终端用户、存储系统以及HPA。它们包含核心指标以及许多非核心指标，其中由于非核心指标本身不能被Kubernetes所解析，此时就需要依赖于用户选择第三方解决方案。如下图：

![](/images/posts/06_k8s/16/3.png)


> 一个可以同时使用资源指标API和自定义指标API的组件是HPAv2，其实现了通过观察指标实现自动扩容和缩容。而目前资源指标API的实现主流是`metrics-server`。
> 
> 自1.8版本后，容器的cpu和内存资源占用利用率都可以通过客户端指标API直接调用，从而获取资源使用情况，要知道的是API本身并不存储任何指标数据，仅仅提供资源占用率的实时监测数据。

资源指标和其他的API指标并没有啥区别，它是通过API Server的URL路径`/apis/metrics.k8s.io/`进行存取，只有在k8s集群内部署了`metrics-server`应用才能只用API，其简单的结构图如下：

![](/images/posts/06_k8s/16/4.png)

Heapster。 Metrics Server 通过 Kubernetes 聚合 器（ kube- aggregator） 注册 到 主 API Server 之上， 而后 基于 kubelet 的 Summary API 收集 每个 节 点上 的 指标 数据， 并将 它们 存储 于 内存 中 然后 以 指标 API 格式 提供，如下图：

![](/images/posts/06_k8s/16/5.png)

> Metrics Server基于 内存 存储， 重 启 后 数据 将 全部 丢失， 而且 它 仅能 留存 最近 收集 到 的 指标 数据， 因此， 如果 用户 期望 访问 历史 数据， 就不 得不 借助于 第三方 的 监控 系统（ 如 Prometheus 等）。
> 
> 一般说来， Metrics Server 在 每个 集群 中 仅 会 运行 一个 实例， 启动 时， 它将 自动 初始化 与 各 节点 的 连接， 因此 出于 安全 方面 的 考虑， 它 需要 运行 于 普通 节点 而非 Master 主机 之上。 直接 使用 项目 本身 提供 的 资源 配置 清单 即 能 轻松 完成 metrics- server 的 部署。


[官方YAML链接](https://github.com/kubernetes/kubernetes/blob/v1.11.2/cluster/addons/metrics-server/)

```
[root@k8s-master metrics-server]# ll
总用量 64
-rw-r--r-- 1 root root   398 1月   2 14:07 auth-delegator.yaml
-rw-r--r-- 1 root root   419 1月   2 14:08 auth-reader.yaml
-rw-r--r-- 1 root root   391 1月   2 19:34 hpa-v2-demo.yaml
-rw-r--r-- 1 root root   393 1月   2 14:09 metrics-apiservice.yaml
-rw-r--r-- 1 root root  2767 1月   2 14:44 metrics-server-deployment.yaml
-rw-r--r-- 1 root root   336 1月   2 14:10 metrics-server-service.yaml
-rw-r--r-- 1 root root   817 1月   2 14:39 resource-reader.yaml

#修改下面这个文件的部分内容
[root@k8s-master metrics-server]# vim metrics-server-deployment.yaml
    spec:
      priorityClassName: system-cluster-critical
      serviceAccountName: metrics-server
      containers:
      - name: metrics-server
        image: k8s.gcr.io/metrics-server-amd64:v0.2.1
        command:
        - /metrics-server
#        - --source=kubernetes.summary_api:''  下面这一条必须加，默认端口为10255，在当前环境不知晓的情况下给禁用了，改用10250
        - --source=kubernetes.summary_api:https://kubernetes.default?kubeletHttps=true&kubeletPort=10250&insecure=true

#由于启动容器还需要权限获取数据，需要在resource-reader.yaml文件中增加nodes/stats
[root@k8s-master metrics-server]# vim resource-reader.yaml 
....
rules:
- apiGroups:
  - ""
  resources:
  - pods
  - nodes
  - nodes/stats
  - namespaces
  
#部署开始
[root@k8s-master metrics-server]# kubectl apply -f .

[root@k8s-master metrics-server]# kubectl api-versions |grep metrics
metrics.k8s.io/v1beta1

#检查资源指标API的可用性
[root@k8s-master metrics-server]# kubectl get --raw "/apis/metrics.k8s.io/v1beta1/nodes"
{"kind":"NodeMetricsList","apiVersion":"metrics.k8s.io/v1beta1","metadata":{"selfLink":"/apis/metrics.k8s.io/v1beta1/nodes"},"items":[{"metadata":{"name":"k8s-master","selfLink":"/apis/metrics.k8s.io/v1beta1/nodes/k8s-master","creationTimestamp":"2021-01-02T06:47:49Z"},"timestamp":"2021-01-02T06:47:00Z","window":"1m0s","usage":{"cpu":"490m","memory":"539616Ki"}},{"metadata":{"name":"k8s-node01","selfLink":"/apis/metrics.k8s.io/v1beta1/nodes/k8s-node01","creationTimestamp":"2021-01-02T06:47:49Z"},"timestamp":"2021-01-02T06:47:00Z","window":"1m0s","usage":{"cpu":"80m","memory":"882096Ki"}},{"metadata":{"name":"k8s-node02","selfLink":"/apis/metrics.k8s.io/v1beta1/nodes/k8s-node02","creationTimestamp":"2021-01-02T06:47:49Z"},"timestamp":"2021-01-02T06:47:00Z","window":"1m0s","usage":{"cpu":"73m","memory":"831892Ki"}}]}

[root@k8s-master metrics-server]# kubectl get pods -n kube-system |grep metrics
metrics-server-v0.2.1-58f847b545-6ktr7   2/2     Running   0          47m
```

以上如果内容没有做修改的话，会出现容器跑不起来一直处于`CrashLoopBackOff`状态，或者出现权限拒绝的问题。可以通过`kubectl logs`进行查看相关的日志。下面使用`kubectl top`命令进行查看资源信息：

```
[root@k8s-master metrics-server]# kubectl top nodes
NAME         CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%   
k8s-master   524m         26%    516Mi           59%       
k8s-node01   87m          4%     848Mi           49%       
k8s-node02   126m         6%     1064Mi          61%       

[root@k8s-master metrics-server]# kubectl top pod -l k8s-app=kube-dns --containers=true -n kube-system
POD                        NAME      CPU(cores)   MEMORY(bytes)   
coredns-5c98db65d4-cn7vm   coredns   2m           20Mi            
coredns-5c98db65d4-lv92m   coredns   28m          12Mi            
coredns-5c98db65d4-xd4td   coredns   2m           17Mi        
```

## 二、监控指标监控之prometheus
### Prometheus概述
除了前面的资源指标（如CPU、内存）以外，用户或管理员需要了解更多的指标数据，比如`Kubernetes`指标、容器指标、节点资源指标以及应用程序指标等等。自定义指标API允许请求任意的指标，其指标API的实现要指定相应的后端监视系统。而`Prometheus`是第一个开发了相应适配器的监控系统。这个适用于`Prometheus`的`Kubernetes Customm Metrics Adapter`是属于Github上的k8s-prometheus-adapter项目提供的。其原理图如下：

![](/images/posts/06_k8s/16/6.png)


> 要知道的是`prometheus`本身就是一监控系统，也分为`server`端和`agent`端，`server`端从被监控主机获取数据，而`agent`端需要部署一个`node_exporter`，主要用于数据采集和暴露节点的数据，那么 在获取Pod级别或者是mysql等多种应用的数据，也是需要部署相关的`exporter`。我们可以通过`PromQL`的方式对数据进行查询，但是由于本身prometheus属于第三方的 解决方案，原生的k8s系统并不能对`Prometheus`的自定义指标进行解析，就需要借助于`k8s-prometheus-adapter`将这些指标数据查询接口转换为标准的`Kubernetes`自定义指标。

Prometheus是一个开源的服务监控系统和时序数据库，其提供了通用的数据模型和快捷数据采集、存储和查询接口。它的核心组件Prometheus服务器定期从静态配置的监控目标或者基于服务发现自动配置的目标中进行拉取数据，新拉取到啊的 数据大于配置的内存缓存区时，数据就会持久化到存储设备当中。Prometheus组件架构图如下：

![](/images/posts/06_k8s/16/7.png)

> 如上图，每个被监控的主机都可以通过专用的`exporter`程序提供输出监控数据的接口，并等待`Prometheus`服务器周期性的进行数据抓取。如果存在告警规则，则抓取到数据之后会根据规则进行计算，满足告警条件则会生成告警，并发送到`Alertmanager`完成告警的汇总和分发。当被监控的目标有主动推送数据的需求时，可以以`Pushgateway`组件进行接收并临时存储数据，然后等待`Prometheus`服务器完成数据的采集。

任何被监控的目标都需要事先纳入到监控系统中才能进行时序数据采集、存储、告警和展示，监控目标可以通过配置信息以静态形式指定，也可以让Prometheus通过服务发现的机制进行动态管理。下面是组件的一些解析：

- 监控代理程序：如node_exporter：收集主机的指标数据，如平均负载、CPU、内存、磁盘、网络等等多个维度的指标数据。
- kubelet（cAdvisor）：收集容器指标数据，也是K8S的核心指标收集，每个容器的相关指标数据包括：CPU使用率、限额、文件系统读写限额、内存使用率和限额、网络报文发送、接收、丢弃速率等等。
- API Server：收集API Server的性能指标数据，包括控制队列的性能、请求速率和延迟时长等等
- etcd：收集etcd存储集群的相关指标数据
- kube-state-metrics：该组件可以派生出k8s相关的多个指标数据，主要是资源类型相关的计数器和元数据信息，包括制定类型的对象总数、资源限额、容器状态以及Pod资源标签系列等。

> Prometheus 能够 直接 把 Kubernetes API Server 作为 服务 发现 系统 使用 进而 动态 发现 和 监控 集群 中的 所有 可被 监控 的 对象。 这里 需要 特别 说明 的 是， Pod 资源 需要 添加 下列 注解 信息 才 能被 Prometheus 系统 自动 发现 并 抓取 其 内建 的 指标 数据。


- prometheus. io/ scrape： 用于 标识 是否 需要 被 采集 指标 数据， 布尔 型 值， true 或 false。
- prometheus. io/ path： 抓取 指标 数据 时 使用 的 URL 路径， 一般 为/ metrics。
- prometheus. io/ port： 抓取 指标 数据 时 使 用的 套 接 字 端口， 如 8080。
 

> 另外， 仅 期望 Prometheus 为 后端 生成 自定义 指标 时 仅 部署 Prometheus 服务器 即可， 它 甚至 也不 需要 数据 持久 功能。 但 若要 配置 完整 功能 的 监控 系统， 管理员 还需 要在 每个 主机 上 部署 node_ exporter、 按 需 部署 其他 特有 类型 的 exporter 以及 Alertmanager。

### 2、Prometheus部署
由于官方的YAML部署方式需要使用到PVC，这里使用马哥提供的学习类型的部署，具体生产还是需要根据官方的建议进行。[本次部署的YAML](http://blog.huyouba1.ltd:81/k8s-prom.tar.gz)

#### 2.1、创建名称空间prom
```
[root@k8s-master ~]# tar xf k8s-prom.tar.gz && cd k8s-prom
[root@k8s-master k8s-prom]# kubectl apply -f namespace.yaml 
namespace/prom created
```
#### 2.2、部署node_exporter
```
[root@k8s-master k8s-prom]# kubectl apply -f node_exporter/
daemonset.apps/prometheus-node-exporter created
service/prometheus-node-exporter created

[root@k8s-master k8s-prom]# kubectl get pods -n prom
NAME                             READY     STATUS    RESTARTS   AGE
prometheus-node-exporter-6srrq   1/1       Running   0          32s
prometheus-node-exporter-fftmc   1/1       Running   0          32s
prometheus-node-exporter-qlr8d   1/1       Running   0          32s
```

#### 2.3、部署prometheus-server
```
[root@k8s-master k8s-prom]# kubectl apply -f prometheus/
configmap/prometheus-config unchanged
deployment.apps/prometheus-server configured
clusterrole.rbac.authorization.k8s.io/prometheus configured
serviceaccount/prometheus unchanged
clusterrolebinding.rbac.authorization.k8s.io/prometheus configured
service/prometheus unchanged


[root@k8s-master k8s-prom]# kubectl get all -n prom
NAME                                    READY     STATUS    RESTARTS   AGE
pod/prometheus-node-exporter-6srrq      1/1       Running   0          11m
pod/prometheus-node-exporter-fftmc      1/1       Running   0          11m
pod/prometheus-node-exporter-qlr8d      1/1       Running   0          11m
pod/prometheus-server-66cbd4c6b-j9lqr   1/1       Running   0          4m

NAME                               TYPE        CLUSTER-IP    EXTERNAL-IP   PORT(S)          AGE
service/prometheus                 NodePort    10.96.65.72   <none>        9090:30090/TCP   10m
service/prometheus-node-exporter   ClusterIP   None          <none>        9100/TCP         11m

NAME                                      DESIRED   CURRENT   READY     UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE
daemonset.apps/prometheus-node-exporter   3         3         3         3            3           <none>          11m

NAME                                DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/prometheus-server   1         1         1            1           10m

NAME                                           DESIRED   CURRENT   READY     AGE
replicaset.apps/prometheus-server-65f5d59585   0         0         0         10m
replicaset.apps/prometheus-server-66cbd4c6b    1         1         1         4m
```

#### 2.4、部署kube-sate-metrics
```
[root@k8s-master k8s-prom]# kubectl apply -f kube-state-metrics/
deployment.apps/kube-state-metrics created
serviceaccount/kube-state-metrics created
clusterrole.rbac.authorization.k8s.io/kube-state-metrics created
clusterrolebinding.rbac.authorization.k8s.io/kube-state-metrics created
service/kube-state-metrics created

[root@k8s-master k8s-prom]# kubectl get pods -n prom -o wide
NAME                                  READY     STATUS    RESTARTS   AGE       IP              NODE
kube-state-metrics-78fc9fc745-g66p8   1/1       Running   0          11m       10.244.1.22     k8s-node01
prometheus-node-exporter-6srrq        1/1       Running   0          31m       192.168.56.11   k8s-master
prometheus-node-exporter-fftmc        1/1       Running   0          31m       192.168.56.12   k8s-node01
prometheus-node-exporter-qlr8d        1/1       Running   0          31m       192.168.56.13   k8s-node02
prometheus-server-66cbd4c6b-j9lqr     1/1       Running   0          24m       10.244.0.4      k8s-master
```

#### 2.5、制作证书

```
[root@k8s-master k8s-prometheus-adapter]# cat k8s-prometheus-adapter/custom-metrics-apiserver-deployment.yaml  |grep secret
    secret:
      secretName: cm-adapter-serving-certs

[root@k8s-master metrics-server]# cd /etc/kubernetes/pki/

[root@k8s-master pki]# (umask 077;openssl genrsa -out serving.key 2048)
	Generating RSA private key, 2048 bit long modulus
	......................................................+++
	.....+++
	e is 65537 (0x10001)
	
[root@k8s-master pki]# openssl req -new -key serving.key  -out serving.csr -subj "/CN=serving"

[root@k8s-master pki]# openssl x509 -req -in serving.csr  -CA ./ca.crt  -CAkey ./ca.key  -CAcreateserial -out serving.crt -days 3650

[root@k8s-master pki]# ls serving*
serving.crt  serving.csr  serving.key

[root@k8s-master pki]# kubectl create  secret  generic  cm-adapter-serving-certs --from-file=serving.crt=./serving.crt --from-file=serving.key=./serving.key -n prom
secret/cm-adapter-serving-certs created

[root@k8s-master pki]# kubectl get secrets -n prom
	NAME                             TYPE                                  DATA   AGE
	cm-adapter-serving-certs         Opaque                                2      9s
```


#### 2.6、部署k8s-prometheus-adapter
如果由于历史版本更新原因这里自带的`custom-metrics-apiserver-deployment.yaml`和`custom-metrics-config-map.yaml`可能会有点问题，需要下载k8s-prometheus-adapter项目中的这2个文件

```
[root@k8s-master k8s-prometheus-adapter]# wget https://raw.githubusercontent.com/DirectXMan12/k8s-prometheus-adapter/master/deploy/manifests/custom-metrics-apiserver-deployment.yaml

[root@k8s-master k8s-prometheus-adapter]# vim k8s-prometheus-adapter/custom-metrics-apiserver-deployment.yaml #修改名称空间为prom

[root@k8s-master k8s-prometheus-adapter]# wget https://raw.githubusercontent.com/DirectXMan12/k8s-prometheus-adapter/master/deploy/manifests/custom-metrics-config-map.yaml  #也需要修改名称空间为prom

[root@k8s-master k8s-prom]# kubectl apply -f k8s-prometheus-adapter/
clusterrolebinding.rbac.authorization.k8s.io/custom-metrics:system:auth-delegator created
rolebinding.rbac.authorization.k8s.io/custom-metrics-auth-reader created
deployment.apps/custom-metrics-apiserver created
clusterrolebinding.rbac.authorization.k8s.io/custom-metrics-resource-reader created
serviceaccount/custom-metrics-apiserver created
service/custom-metrics-apiserver created
apiservice.apiregistration.k8s.io/v1beta1.custom.metrics.k8s.io created
clusterrole.rbac.authorization.k8s.io/custom-metrics-server-resources created
clusterrole.rbac.authorization.k8s.io/custom-metrics-resource-reader created
clusterrolebinding.rbac.authorization.k8s.io/hpa-controller-custom-metrics created

[root@k8s-master k8s-prom]# kubectl get pods -n prom
NAME                                       READY     STATUS    RESTARTS   AGE
custom-metrics-apiserver-65f545496-l5md9   1/1       Running   0          7m
kube-state-metrics-78fc9fc745-g66p8        1/1       Running   0          40m
prometheus-node-exporter-6srrq             1/1       Running   0          1h
prometheus-node-exporter-fftmc             1/1       Running   0          1h
prometheus-node-exporter-qlr8d             1/1       Running   0          1h
prometheus-server-66cbd4c6b-j9lqr          1/1       Running   0          53m

[root@k8s-master k8s-prom]# kubectl api-versions |grep custom
custom.metrics.k8s.io/v1beta1

[root@k8s-master ~]# kubectl get svc -n  prom
NAME                       TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE
custom-metrics-apiserver   ClusterIP   10.99.14.141    <none>        443/TCP          11h
kube-state-metrics         ClusterIP   10.107.23.237   <none>        8080/TCP         11h
prometheus                 NodePort    10.96.65.72     <none>        9090:30090/TCP   11h
prometheus-node-exporter   ClusterIP   None            <none>        9100/TCP         11h
```

访问IP:30090，如下图：选择 需要查看的指标，点击`Execute`

![](/images/posts/06_k8s/16/8.png)

### 3、Grafana数据展示
```
[root@k8s-master k8s-prom]# cat grafana.yaml 
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: monitoring-grafana
  namespace: prom  ##修改名称空间
spec:
  replicas: 1
  template:
    metadata:
      labels:
        task: monitoring
        k8s-app: grafana
    spec:
      containers:
      - name: grafana
        image: gcr.io/google_containers/heapster-grafana-amd64:v5.0.4
        ports:
        - containerPort: 3000
          protocol: TCP
        volumeMounts:
        - mountPath: /etc/ssl/certs
          name: ca-certificates
          readOnly: true
        - mountPath: /var
          name: grafana-storage
        env:
        #- name: INFLUXDB_HOST
        #  value: monitoring-influxdb  #这里使用的是原先的heapster的grafana的配置文件，需要注释掉这个环境变量
        - name: GF_SERVER_HTTP_PORT
          value: "3000"
          # The following env variables are required to make Grafana accessible via
          # the kubernetes api-server proxy. On production clusters, we recommend
          # removing these env variables, setup auth for grafana, and expose the grafana
          # service using a LoadBalancer or a public IP.
        - name: GF_AUTH_BASIC_ENABLED
          value: "false"
        - name: GF_AUTH_ANONYMOUS_ENABLED
          value: "true"
        - name: GF_AUTH_ANONYMOUS_ORG_ROLE
          value: Admin
        - name: GF_SERVER_ROOT_URL
          # If you're only using the API Server proxy, set this value instead:
          # value: /api/v1/namespaces/kube-system/services/monitoring-grafana/proxy
          value: /
      volumes:
      - name: ca-certificates
        hostPath:
          path: /etc/ssl/certs
      - name: grafana-storage
        emptyDir: {}
---
apiVersion: v1
kind: Service
metadata:
  labels:
    # For use as a Cluster add-on (https://github.com/kubernetes/kubernetes/tree/master/cluster/addons)
    # If you are NOT using this as an addon, you should comment out this line.
    kubernetes.io/cluster-service: 'true'
    kubernetes.io/name: monitoring-grafana
  name: monitoring-grafana
  namespace: prom   ##修改名称空间
spec:
  # In a production setup, we recommend accessing Grafana through an external Loadbalancer
  # or through a public IP.
  # type: LoadBalancer
  # You could also use NodePort to expose the service at a randomly-generated port
  # type: NodePort
  ports:
  - port: 80
    targetPort: 3000
  selector:
    k8s-app: grafana
  type: NodePort

    
[root@k8s-master k8s-prom]# kubectl apply -f grafana.yaml 
deployment.apps/monitoring-grafana created
service/monitoring-grafana created

[root@k8s-master k8s-prom]# kubectl get pods -n prom
NAME                                       READY     STATUS    RESTARTS   AGE
custom-metrics-apiserver-65f545496-l5md9   1/1       Running   0          16m
kube-state-metrics-78fc9fc745-g66p8        1/1       Running   0          49m
monitoring-grafana-7c94886cd5-dhcqz        1/1       Running   0          36s
prometheus-node-exporter-6srrq             1/1       Running   0          1h
prometheus-node-exporter-fftmc             1/1       Running   0          1h
prometheus-node-exporter-qlr8d             1/1       Running   0          1h
prometheus-server-66cbd4c6b-j9lqr          1/1       Running   0          1h

[root@k8s-master k8s-prom]# kubectl get svc -n prom
NAME                       TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE
custom-metrics-apiserver   ClusterIP   10.99.14.141    <none>        443/TCP          11h
kube-state-metrics         ClusterIP   10.107.23.237   <none>        8080/TCP         11h
monitoring-grafana         NodePort    10.98.174.125   <none>        80:31689/TCP     10h
prometheus                 NodePort    10.96.65.72     <none>        9090:30090/TCP   11h
prometheus-node-exporter   ClusterIP   None            <none>        9100/TCP         11h
```
访问grafana的地址：IP:31689，默认是没有kubernetes的模板的，可以到grafana.com中去下载相关的kubernetes模板。

![](/images/posts/06_k8s/16/9.png)

![](/images/posts/06_k8s/16/10.png)
